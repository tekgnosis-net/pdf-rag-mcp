# Runtime configuration for PDF RAG MCP services.

# PDF parsing backend. Options: "docling" (default) or "pymupdf".
PDF_PARSER=docling

# Embedding backend. "local" uses sentence-transformers, "openai" calls remote API.
EMBEDDING_BACKEND=local
# Local embedding model name (only used when EMBEDDING_BACKEND=local).
SENTENCE_TRANSFORMER_MODEL=sentence-transformers/all-MiniLM-L6-v2
# Target device for embeddings: "cpu" (default) or "cuda".
EMBEDDING_DEVICE=cpu

# Remote embedding settings (only used when EMBEDDING_BACKEND=openai).
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_API_KEY=
OPENAI_MODEL=text-embedding-3-large

# Optional overrides for CUDA wheel installation (used when EMBEDDING_DEVICE=cuda).
TORCH_CUDA_INDEX_URL=https://download.pytorch.org/whl/cu124
TORCH_CUDA_PACKAGES=torch torchvision torchaudio

# Persistence configuration.
DATABASE_URL=sqlite:///data/markdown.db
VECTOR_STORE_PATH=data/vector_store
DATA_DIR=/app/data

# Frontend assets served by FastAPI.
FRONTEND_DIST_PATH=/app/frontend/dist

# Directory watcher configuration. Files dropped into WATCH_DIR are
# automatically ingested when WATCH_ENABLED=true.
WATCH_ENABLED=true
WATCH_DIR=/app/data/pdfs
WATCH_POLL_INTERVAL=10
MAX_PROCESS_ATTEMPTS=10

# Logging verbosity for the backend (e.g. DEBUG, INFO, WARNING).
LOG_LEVEL=INFO
