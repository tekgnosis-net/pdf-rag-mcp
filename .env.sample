# Runtime configuration for PDF RAG MCP services.

# PDF parsing backend. Options: "pymupdf" (default) or "docling".
PDF_PARSER=pymupdf

# Embedding backend. "local" uses sentence-transformers, "openai" calls remote API.
EMBEDDING_BACKEND=local
# Local embedding model name (only used when EMBEDDING_BACKEND=local).
SENTENCE_TRANSFORMER_MODEL=sentence-transformers/all-MiniLM-L6-v2
# Target device for embeddings: "cpu" (default) or "cuda".
EMBEDDING_DEVICE=cpu

# Remote embedding settings (only used when EMBEDDING_BACKEND=openai).
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_API_KEY=
OPENAI_MODEL=text-embedding-3-large

# Optional overrides for CUDA wheel installation (used when EMBEDDING_DEVICE=cuda).
TORCH_CUDA_INDEX_URL=https://download.pytorch.org/whl/cu124
TORCH_CUDA_PACKAGES=torch torchvision torchaudio

# Persistence configuration.
DATABASE_URL=sqlite:///data/markdown.db
VECTOR_STORE_PATH=data/vector_store
DATA_DIR=/app/data

# Frontend assets served by FastAPI.
FRONTEND_DIST_PATH=/app/frontend/dist

# Logging verbosity for the backend (e.g. DEBUG, INFO, WARNING).
LOG_LEVEL=INFO
